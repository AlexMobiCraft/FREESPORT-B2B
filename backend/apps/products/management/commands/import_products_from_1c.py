"""
Management –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ 1–° —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π ProductVariant

Story 13.2: –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –∏–º–ø–æ—Ä—Ç–∞ –∏–∑ 1–° –¥–ª—è ProductVariant

–ù–æ–≤—ã–π workflow –∏–º–ø–æ—Ä—Ç–∞:
1. goods.xml ‚Üí Product (–±–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, base_images)
2. offers.xml ‚Üí ProductVariant (SKU, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)
3. Default variants ‚Üí ProductVariant –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
4. prices.xml ‚Üí ProductVariant (—Ü–µ–Ω—ã)
5. rests.xml ‚Üí ProductVariant (–æ—Å—Ç–∞—Ç–∫–∏)

Strategy: Batch-Level Atomicity
-------------------------------
Due to the potentially large size of XML files (hundreds of megabytes) and memory constraints,
we explicitly avoid wrapping the entire import process in a single atomic transaction.
Instead, we use batch-level processing where each batch (default 500 items) is processed
within its own transaction (via VariantImportProcessor).

Trade-offs:
- Pros: Significantly lower memory usage, resilient to timeouts, partial progress is saved.
- Cons: Failure mid-import requires a re-run or manual cleanup (ImportSession tracks state).
- Recovery: ImportSession.report logs progress, allowing analysis of where failure occurred.
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import Any, cast

from django.core.management import call_command
from django.core.management.base import BaseCommand, CommandError
from tqdm import tqdm

from apps.products.models import Brand, Category, ImportSession, Product, ProductVariant
from apps.products.services.parser import XMLDataParser
from apps.products.services.variant_import import VariantImportProcessor


class Command(BaseCommand):
    """
    –ò–º–ø–æ—Ä—Ç –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ XML —Ñ–∞–π–ª–æ–≤ 1–° (CommerceML 3.1) —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
    ProductVariant

    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        python manage.py import_products_from_1c --data-dir /path/to/1c/data
        python manage.py import_products_from_1c --data-dir /path --dry-run
        python manage.py import_products_from_1c --data-dir /path --batch-size=500
        python manage.py import_products_from_1c --data-dir /path --file-type=goods
        python manage.py import_products_from_1c --data-dir /path --clear-existing
        python manage.py import_products_from_1c --data-dir /path --variants-only
    """

    help = "–ò–º–ø–æ—Ä—Ç –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤ 1–° (CommerceML 3.1) " "—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π ProductVariant"

    def add_arguments(self, parser):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥—ã"""
        parser.add_argument(
            "--data-dir",
            type=str,
            default=None,
            help=("–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å XML —Ñ–∞–π–ª–∞–º–∏ –∏–∑ 1–°. " "–ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ONEC_DATA_DIR –∏–∑ settings."),
        )
        parser.add_argument(
            "--dry-run",
            action="store_true",
            help="–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –±–µ–∑ –∑–∞–ø–∏—Å–∏ –≤ –ë–î",
        )
        parser.add_argument(
            "--batch-size",
            type=int,
            default=500,
            help="–†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ –¥–ª—è bulk –æ–ø–µ—Ä–∞—Ü–∏–π (default: 500, NFR4)",
        )
        parser.add_argument(
            "--skip-validation",
            action="store_true",
            help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–∞",
        )
        parser.add_argument(
            "--file-type",
            type=str,
            choices=["goods", "offers", "prices", "rests", "all"],
            default="all",
            help="–í—ã–±–æ—Ä–æ—á–Ω—ã–π –∏–º–ø–æ—Ä—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–∏–ø–∞ —Ñ–∞–π–ª–æ–≤ (default: all)",
        )
        parser.add_argument(
            "--clear-existing",
            action="store_true",
            help=("–û—á–∏—Å—Ç–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º " "(–í–ù–ò–ú–ê–ù–ò–ï: —É–¥–∞–ª–∏—Ç –≤—Å–µ —Ç–æ–≤–∞—Ä—ã –∏ –≤–∞—Ä–∏–∞–Ω—Ç—ã)"),
        )
        parser.add_argument(
            "--skip-backup",
            action="store_true",
            help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ backup –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º",
        )
        parser.add_argument(
            "--skip-images",
            action="store_true",
            help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏–º–ø–æ—Ä—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ (—Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)",
        )
        parser.add_argument(
            "--skip-default-variants",
            action="store_true",
            help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ default variants –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤",
        )
        parser.add_argument(
            "--variants-only",
            action="store_true",
            help=(
                "–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç—ã (offers.xml, prices.xml, rests.xml) "
                "–±–µ–∑ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (goods.xml). "
                "–¢—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤."
            ),
        )
        parser.add_argument(
            "--celery-task-id",
            type=str,
            default=None,
            help=(
                "ID Celery –∑–∞–¥–∞—á–∏ –¥–ª—è —Å–≤—è–∑–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–µ—Å—Å–∏–µ–π –∏–º–ø–æ—Ä—Ç–∞. "
                "–ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω, –∫–æ–º–∞–Ω–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–µ—Å—Å–∏—é –≤–º–µ—Å—Ç–æ "
                "—Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π."
            ),
        )
        parser.add_argument(
            "--keep-files",
            action="store_true",
            help="–ù–µ —É–¥–∞–ª—è—Ç—å —Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)",
        )
        parser.add_argument(
            "--import-session-id",
            type=int,
            default=None,
            help="ID —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–µ—Å—Å–∏–∏ ImportSession –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ –ª–æ–≥–æ–≤.",
        )

    def handle(self, *args, **options):
        """–û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∫–æ–º–∞–Ω–¥—ã"""
        from django.conf import settings

        data_dir = options["data_dir"]
        if not data_dir:
            data_dir = settings.ONEC_DATA_DIR

        dry_run = options.get("dry_run", False)
        batch_size = options.get("batch_size", 500)
        skip_validation = options.get("skip_validation", False)
        file_type = options.get("file_type", "all")
        clear_existing = options.get("clear_existing", False)
        skip_backup = options.get("skip_backup", False)
        skip_images = options.get("skip_images", False)
        skip_default_variants = options.get("skip_default_variants", False)
        variants_only = options.get("variants_only", False)
        celery_task_id = options.get("celery_task_id", None)
        import_session_id = options.get("import_session_id", None)

        # --variants-only –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç file_type
        if variants_only:
            file_type = "offers"  # –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ offers + prices + rests

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if not os.path.exists(data_dir):
            raise CommandError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {data_dir}")

        if not os.path.isdir(data_dir):
            raise CommandError(f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π: {data_dir}")

        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if file_type == "all":
            required_subdirs = ["goods", "offers", "prices", "rests", "priceLists"]
            for subdir in required_subdirs:
                subdir_path = os.path.join(data_dir, subdir)
                if not os.path.exists(subdir_path):
                    raise CommandError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {subdir}")
        elif file_type == "offers" or variants_only:
            # –î–ª—è --variants-only –Ω—É–∂–Ω—ã —Ç–æ–ª—å–∫–æ offers, prices, rests
            required_subdirs = ["offers", "prices", "rests"]
            for subdir in required_subdirs:
                subdir_path = os.path.join(data_dir, subdir)
                if not os.path.exists(subdir_path):
                    raise CommandError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è " f"–∏–º–ø–æ—Ä—Ç–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {subdir}")

        if dry_run:
            self.stdout.write(self.style.WARNING("üîç DRY RUN MODE: –ò–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î"))
            return self._dry_run_import(data_dir)

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π backup –ø–µ—Ä–µ–¥ –ø–æ–ª–Ω—ã–º –∏–º–ø–æ—Ä—Ç–æ–º
        if not dry_run and file_type == "all" and not skip_backup:
            self.stdout.write(self.style.WARNING("\nüíæ –°–æ–∑–¥–∞–Ω–∏–µ backup –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º..."))
            try:
                call_command("backup_db")
                self.stdout.write(self.style.SUCCESS("‚úÖ Backup —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ"))
            except Exception as e:
                self.stdout.write(self.style.WARNING(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å backup: {e}. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏–º–ø–æ—Ä—Ç..."))

        # –û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        if clear_existing:
            self._clear_existing_data()

        # –í—ã–≤–æ–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–º–ø–æ—Ä—Ç–∞
        self.stdout.write("\n" + "=" * 60)
        if variants_only:
            self.stdout.write("üìä –ü–ê–†–ê–ú–ï–¢–†–´ –ò–ú–ü–û–†–¢–ê (–¢–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç—ã):")
        else:
            self.stdout.write("üìä –ü–ê–†–ê–ú–ï–¢–†–´ –ò–ú–ü–û–†–¢–ê (ProductVariant mode):")
        self.stdout.write(f"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {data_dir}")
        self.stdout.write(f"   –¢–∏–ø —Ñ–∞–π–ª–æ–≤: {file_type}")
        self.stdout.write(f"   Variants only: {variants_only}")
        self.stdout.write(f"   Batch size: {batch_size}")
        self.stdout.write(f"   Skip validation: {skip_validation}")
        self.stdout.write(f"   Skip backup: {skip_backup}")
        self.stdout.write(f"   Skip images: {skip_images}")
        self.stdout.write(f"   Skip default variants: {skip_default_variants}")
        if import_session_id:
            self.stdout.write(f"   Import session ID: {import_session_id}")
        self.stdout.write("=" * 60)

        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–ª–∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–µ—Å—Å–∏–∏ –∏–º–ø–æ—Ä—Ç–∞
        session_type = ImportSession.ImportType.VARIANTS if variants_only else ImportSession.ImportType.CATALOG

        session = None

        # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ import_session_id (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏)
        if import_session_id:
            try:
                session = ImportSession.objects.get(pk=import_session_id)
                session.status = ImportSession.ImportStatus.IN_PROGRESS
                if celery_task_id:
                    session.celery_task_id = celery_task_id
                session.save(update_fields=["status", "celery_task_id", "updated_at"])
                self.stdout.write(self.style.SUCCESS(f"\n‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è —Å–µ—Å—Å–∏—è –∏–º–ø–æ—Ä—Ç–∞ ID: {session.pk}"))
            except ImportSession.DoesNotExist:
                self.stdout.write(self.style.WARNING(f"\n‚ö†Ô∏è –°–µ—Å—Å–∏—è —Å id={import_session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."))

        # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –ø–æ celery_task_id
        if session is None and celery_task_id:
            try:
                session = ImportSession.objects.get(celery_task_id=celery_task_id)
                session.status = ImportSession.ImportStatus.IN_PROGRESS
                session.save(update_fields=["status", "updated_at"])
                self.stdout.write(self.style.SUCCESS(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å–µ—Å—Å–∏—è –ø–æ Celery Task ID: {session.pk}"))
            except ImportSession.DoesNotExist:
                pass

        # 3. –ï—Å–ª–∏ –≤—Å—ë –µ—â–µ –Ω–µ—Ç - —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
        if session is None:
            session = ImportSession.objects.create(
                import_type=session_type,
                status=ImportSession.ImportStatus.IN_PROGRESS,
                celery_task_id=celery_task_id,
            )
            self.stdout.write(self.style.SUCCESS(f"\n‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ù–û–í–ê–Ø —Å–µ—Å—Å–∏—è –∏–º–ø–æ—Ä—Ç–∞ ID: {session.pk}"))

        session_id = session.pk

        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
            parser = XMLDataParser()

            # VariantImportProcessor –¥–ª—è Product + ProductVariant
            # + Categories + Brands + PriceTypes
            # (–º–µ—Ç–æ–¥—ã process_categories, process_brands, process_price_types
            # –º–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ Story 27.1)
            variant_processor = VariantImportProcessor(
                session_id=session_id,
                batch_size=batch_size,
                skip_validation=skip_validation,
            )

            # –®–ê–ì 0.5: –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ groups.xml
            if file_type in ["all", "goods"]:
                variant_processor.log_progress("–ù–∞—á–∞–ª–æ –∏–º–ø–æ—Ä—Ç–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
                self._import_categories(data_dir, parser, variant_processor)

            # –®–ê–ì 0.6: –ó–∞–≥—Ä—É–∑–∫–∞ –±—Ä–µ–Ω–¥–æ–≤ –∏–∑ propertiesGoods.xml
            if file_type in ["all", "goods"]:
                variant_processor.log_progress("–ù–∞—á–∞–ª–æ –∏–º–ø–æ—Ä—Ç–∞ –±—Ä–µ–Ω–¥–æ–≤...")
                self._import_brands(data_dir, parser, variant_processor)

            # –®–ê–ì 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∏–ø–æ–≤ —Ü–µ–Ω –∏–∑ priceLists*.xml
            if file_type in ["all", "prices"]:
                variant_processor.log_progress("–ù–∞—á–∞–ª–æ –∏–º–ø–æ—Ä—Ç–∞ —Ç–∏–ø–æ–≤ —Ü–µ–Ω...")
                self._import_price_types(data_dir, parser, variant_processor)

            # –®–ê–ì 2: –ü–∞—Ä—Å–∏–Ω–≥ goods.xml ‚Üí Product (–±–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
            if file_type in ["all", "goods"]:
                variant_processor.log_progress("–ù–∞—á–∞–ª–æ –∏–º–ø–æ—Ä—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤ (goods.xml)...")
                self._import_products_from_goods(data_dir, parser, variant_processor, skip_images)

            # –®–ê–ì 3: –ü–∞—Ä—Å–∏–Ω–≥ offers.xml ‚Üí ProductVariant
            if file_type in ["all", "offers"]:
                variant_processor.log_progress("–ù–∞—á–∞–ª–æ –∏–º–ø–æ—Ä—Ç–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (offers.xml)...")
                self._import_variants_from_offers(data_dir, parser, variant_processor, skip_images)

            # –®–ê–ì 3.5: –°–æ–∑–¥–∞–Ω–∏–µ default variants –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
            if file_type in ["all", "offers"] and not skip_default_variants:
                variant_processor.log_progress("–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤...")
                self._create_default_variants(variant_processor)

            # –®–ê–ì 4: –ü–∞—Ä—Å–∏–Ω–≥ prices.xml ‚Üí ProductVariant (—Ü–µ–Ω—ã)
            if file_type in ["all", "prices", "offers"]:
                variant_processor.log_progress("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω –∏–∑ prices.xml...")
                self._import_variant_prices(data_dir, parser, variant_processor)

            # –®–ê–ì 5: –ü–∞—Ä—Å–∏–Ω–≥ rests.xml ‚Üí ProductVariant (–æ—Å—Ç–∞—Ç–∫–∏)
            if file_type in ["all", "rests", "offers"]:
                variant_processor.log_progress("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ –∏–∑ rests.xml...")
                self._import_variant_stocks(data_dir, parser, variant_processor)

            # –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
            variant_processor.finalize_session(status=ImportSession.ImportStatus.COMPLETED)

            # –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
            if not dry_run and not options.get("keep_files", False):
                self._cleanup_files(data_dir, file_type)

            # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._print_stats(variant_processor.get_stats())

        except Exception as e:
            self.stdout.write(self.style.ERROR(f"\n‚ùå –û–®–ò–ë–ö–ê –ò–ú–ü–û–†–¢–ê: {e}"))
            session.status = ImportSession.ImportStatus.FAILED
            session.error_message = str(e)
            session.save()
            raise CommandError(f"–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {e}")

    def _import_categories(self, data_dir: str, parser: XMLDataParser, processor: VariantImportProcessor) -> None:
        """–ò–º–ø–æ—Ä—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ groups.xml"""
        self.stdout.write("\nüìÅ –®–∞–≥ 0.5: –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
        groups_files = self._collect_xml_files(data_dir, "groups", "groups.xml")

        if groups_files:
            total_categories = 0
            for file_path in groups_files:
                categories_data = parser.parse_groups_xml(file_path)
                result = processor.process_categories(categories_data)
                total_categories += result["created"] + result["updated"]
                self.stdout.write(f"   ‚Ä¢ {Path(file_path).name}: –∫–∞—Ç–µ–≥–æ—Ä–∏–π {len(categories_data)}")

                if result["cycles_detected"] > 0:
                    self.stdout.write(
                        self.style.WARNING(f"   ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫: " f"{result['cycles_detected']}")
                    )

            self.stdout.write(self.style.SUCCESS(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–≤—Å–µ–≥–æ): {total_categories}"))
        else:
            self.stdout.write(self.style.WARNING("   ‚ö†Ô∏è –§–∞–π–ª—ã groups.xml –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"))

    def _import_brands(self, data_dir: str, parser: XMLDataParser, processor: VariantImportProcessor) -> None:
        """–ò–º–ø–æ—Ä—Ç –±—Ä–µ–Ω–¥–æ–≤ –∏–∑ propertiesGoods.xml"""
        self.stdout.write("\nüè∑Ô∏è  –®–∞–≥ 0.6: –ó–∞–≥—Ä—É–∑–∫–∞ –±—Ä–µ–Ω–¥–æ–≤...")
        properties_files = self._collect_xml_files(data_dir, "propertiesGoods", "propertiesGoods.xml")

        if properties_files:
            total_brands = 0
            total_mappings = 0
            for file_path in properties_files:
                brands_data = parser.parse_properties_goods_xml(file_path)
                result = processor.process_brands(brands_data)
                total_brands += result["brands_created"]
                total_mappings += result["mappings_created"]
                self.stdout.write(f"   ‚Ä¢ {Path(file_path).name}: –±—Ä–µ–Ω–¥–æ–≤ {len(brands_data)}")

            self.stdout.write(self.style.SUCCESS(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ –±—Ä–µ–Ω–¥–æ–≤: {total_brands}, –º–∞–ø–ø–∏–Ω–≥–æ–≤: {total_mappings}"))
        else:
            self.stdout.write(self.style.WARNING("   ‚ö†Ô∏è –§–∞–π–ª—ã propertiesGoods*.xml –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"))

    def _import_price_types(self, data_dir: str, parser: XMLDataParser, processor: VariantImportProcessor) -> None:
        """–ò–º–ø–æ—Ä—Ç —Ç–∏–ø–æ–≤ —Ü–µ–Ω –∏–∑ priceLists.xml"""
        self.stdout.write("\nüìã –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∏–ø–æ–≤ —Ü–µ–Ω...")
        price_list_files = self._collect_xml_files(data_dir, "priceLists", "priceLists.xml")

        if price_list_files:
            total_price_types = 0
            for file_path in price_list_files:
                price_types_data = parser.parse_price_lists_xml(file_path)
                for price_type in price_types_data:
                    processor.process_price_types([price_type])
                total_price_types += len(price_types_data)
                self.stdout.write(f"   ‚Ä¢ {Path(file_path).name}: —Ç–∏–ø–æ–≤ —Ü–µ–Ω {len(price_types_data)}")

            self.stdout.write(self.style.SUCCESS(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–∏–ø–æ–≤ —Ü–µ–Ω (–≤—Å–µ–≥–æ): {total_price_types}"))
        else:
            self.stdout.write(self.style.WARNING("   ‚ö†Ô∏è –§–∞–π–ª—ã priceLists*.xml –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"))

    def _import_products_from_goods(
        self,
        data_dir: str,
        parser: XMLDataParser,
        processor: VariantImportProcessor,
        skip_images: bool,
    ) -> None:
        """–ò–º–ø–æ—Ä—Ç Product –∏–∑ goods.xml (AC1)"""
        self.stdout.write("\nüì¶ –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ Product –∏–∑ goods.xml...")
        goods_files = self._collect_xml_files(data_dir, "goods", "goods.xml")

        if not goods_files:
            self.stdout.write(self.style.WARNING("   ‚ö†Ô∏è –§–∞–π–ª—ã —Ç–æ–≤–∞—Ä–æ–≤ (goods_*.xml) –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–ø—É—Å–∫ —à–∞–≥–∞."))
            return

        for file_path in goods_files:
            goods_data = parser.parse_goods_xml(file_path)
            base_dir = os.path.join(data_dir, "goods", "import_files")

            for i, goods_item in enumerate(tqdm(goods_data, desc=f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ {Path(file_path).name}")):
                processor.process_product_from_goods(
                    cast("dict[str, Any]", goods_item),
                    base_dir=base_dir,
                    skip_images=skip_images,
                )
                if (i + 1) % 20 == 0:
                    processor.log_progress(
                        f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ ({Path(file_path).name}): " f"{i + 1} –∏–∑ {len(goods_data)}"
                    )

            self.stdout.write(f"   ‚Ä¢ {Path(file_path).name}: —Ç–æ–≤–∞—Ä–æ–≤ {len(goods_data)}")

        stats = processor.get_stats()
        self.stdout.write(
            self.style.SUCCESS(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ: {stats['products_created']}, " f"–æ–±–Ω–æ–≤–ª–µ–Ω–æ: {stats['products_updated']}")
        )

    def _import_variants_from_offers(
        self,
        data_dir: str,
        parser: XMLDataParser,
        processor: VariantImportProcessor,
        skip_images: bool,
    ) -> None:
        """–ò–º–ø–æ—Ä—Ç ProductVariant –∏–∑ offers.xml (AC2, AC3, AC4)"""
        self.stdout.write("\nüéÅ –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ ProductVariant –∏–∑ offers.xml...")
        offers_files = self._collect_xml_files(data_dir, "offers", "offers.xml")

        if not offers_files:
            self.stdout.write(self.style.WARNING("   ‚ö†Ô∏è –§–∞–π–ª—ã –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (offers_*.xml) –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–ø—É—Å–∫ —à–∞–≥–∞."))
            return

        for file_path in offers_files:
            offers_data = parser.parse_offers_xml(file_path)
            base_dir = os.path.join(data_dir, "offers", "import_files")
            # Fallback: –ï—Å–ª–∏ –ø–∞–ø–∫–∞ offers/import_files –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–±—É–µ–º goods/import_files
            # (—Ç–∞–∫ –∫–∞–∫ FileRoutingService –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∫–ª–∞–¥–µ—Ç –≤—Å–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ goods/import_files)
            if not os.path.exists(base_dir):
                alt_dir = os.path.join(data_dir, "goods", "import_files")
                if os.path.exists(alt_dir):
                    base_dir = alt_dir
                    self.stdout.write(f"   ‚ÑπÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –∏–∑: {Path(base_dir).relative_to(data_dir)}")

            for i, offer_item in enumerate(tqdm(offers_data, desc=f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ {Path(file_path).name}")):
                processor.process_variant_from_offer(
                    cast("dict[str, Any]", offer_item),
                    base_dir=base_dir,
                    skip_images=skip_images,
                )
                if (i + 1) % 20 == 0:
                    processor.log_progress(
                        f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ ({Path(file_path).name}): " f"{i + 1} –∏–∑ {len(offers_data)}"
                    )

            self.stdout.write(f"   ‚Ä¢ {Path(file_path).name}: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π {len(offers_data)}")

        stats = processor.get_stats()
        self.stdout.write(
            self.style.SUCCESS(
                f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {stats['variants_created']}, "
                f"–æ–±–Ω–æ–≤–ª–µ–Ω–æ: {stats['variants_updated']}, "
                f"–ø—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}"
            )
        )

    def _create_default_variants(self, processor: VariantImportProcessor) -> None:
        """–°–æ–∑–¥–∞–Ω–∏–µ default variants –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (AC5)"""
        self.stdout.write("\nüîÑ –®–∞–≥ 3.5: –°–æ–∑–¥–∞–Ω–∏–µ default variants...")
        count = processor.create_default_variants()
        self.stdout.write(self.style.SUCCESS(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ default variants: {count}"))

    def _import_variant_prices(
        self,
        data_dir: str,
        parser: XMLDataParser,
        processor: VariantImportProcessor,
    ) -> None:
        """–ò–º–ø–æ—Ä—Ç —Ü–µ–Ω –≤ ProductVariant –∏–∑ prices.xml (AC7)"""
        self.stdout.write("\nüí∞ –®–∞–≥ 4: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω ProductVariant –∏–∑ prices.xml...")
        prices_files = self._collect_xml_files(data_dir, "prices", "prices.xml")

        if not prices_files:
            self.stdout.write(self.style.WARNING("   ‚ö†Ô∏è –§–∞–π–ª—ã prices.xml –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"))
            return

        for file_path in prices_files:
            prices_data = parser.parse_prices_xml(file_path)

            for i, price_item in enumerate(tqdm(prices_data, desc=f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ {Path(file_path).name}")):
                processor.update_variant_prices(cast("dict[str, Any]", price_item))
                if (i + 1) % 20 == 0:
                    processor.log_progress(
                        f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω ({Path(file_path).name}): " f"{i + 1} –∏–∑ {len(prices_data)}"
                    )

            self.stdout.write(f"   ‚Ä¢ {Path(file_path).name}: –∑–∞–ø–∏—Å–µ–π —Ü–µ–Ω {len(prices_data)}")

        stats = processor.get_stats()
        self.stdout.write(self.style.SUCCESS(f"   ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ —Ü–µ–Ω: {stats['prices_updated']}"))

    def _import_variant_stocks(
        self,
        data_dir: str,
        parser: XMLDataParser,
        processor: VariantImportProcessor,
    ) -> None:
        """–ò–º–ø–æ—Ä—Ç –æ—Å—Ç–∞—Ç–∫–æ–≤ –≤ ProductVariant –∏–∑ rests.xml (AC8)"""
        self.stdout.write("\nüìä –®–∞–≥ 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ ProductVariant –∏–∑ rests.xml...")
        rests_files = self._collect_xml_files(data_dir, "rests", "rests.xml")

        if not rests_files:
            self.stdout.write(self.style.WARNING("   ‚ö†Ô∏è –§–∞–π–ª—ã rests.xml –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"))
            return

        for file_path in rests_files:
            rests_data = parser.parse_rests_xml(file_path)

            for i, rest_item in enumerate(tqdm(rests_data, desc=f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ {Path(file_path).name}")):
                processor.update_variant_stock(cast("dict[str, Any]", rest_item))
                if (i + 1) % 20 == 0:
                    processor.log_progress(
                        f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ ({Path(file_path).name}): " f"{i + 1} –∏–∑ {len(rests_data)}"
                    )

            self.stdout.write(f"   ‚Ä¢ {Path(file_path).name}: –∑–∞–ø–∏—Å–µ–π –æ—Å—Ç–∞—Ç–∫–æ–≤ {len(rests_data)}")

        stats = processor.get_stats()
        self.stdout.write(self.style.SUCCESS(f"   ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ –æ—Å—Ç–∞—Ç–∫–æ–≤: {stats['stocks_updated']}"))

    def _cleanup_files(self, data_dir: str, file_type: str) -> None:
        """
        –£–¥–∞–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞.
        –£–¥–∞–ª—è–µ—Ç XML —Ñ–∞–π–ª—ã –∏ –æ—á–∏—â–∞–µ—Ç –ø–∞–ø–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
        """
        import shutil

        self.stdout.write(self.style.WARNING("\nüßπ –û—á–∏—Å—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤..."))

        # 1. –£–¥–∞–ª–µ–Ω–∏–µ XML —Ñ–∞–π–ª–æ–≤
        xml_patterns = []
        if file_type in ["all", "goods"]:
            xml_patterns.extend(
                [
                    "goods/goods*.xml",
                    "goods/import*.xml",
                    "goods/groups*.xml",
                    "goods/properties*.xml",
                ]
            )
        if file_type in ["all", "offers"]:
            xml_patterns.extend(
                [
                    "offers/offers*.xml",
                    "offers/rests*.xml",
                    "offers/prices*.xml",
                    "offers/properties*.xml",
                ]
            )
        if file_type in ["all", "prices"]:
            xml_patterns.extend(["prices/prices*.xml", "priceLists/priceLists*.xml"])
        if file_type in ["all", "rests"]:
            xml_patterns.extend(["rests/rests*.xml"])

        deleted_xml_count = 0
        for pattern in xml_patterns:
            for file_path in Path(data_dir).glob(pattern):
                try:
                    file_path.unlink()
                    deleted_xml_count += 1
                except OSError as e:
                    self.stdout.write(self.style.ERROR(f"   ‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {file_path.name}: {e}"))

        self.stdout.write(f"   ‚úÖ –£–¥–∞–ª–µ–Ω–æ XML —Ñ–∞–π–ª–æ–≤: {deleted_xml_count}")

        # 2. –û—á–∏—Å—Ç–∫–∞ –ø–∞–ø–æ–∫ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (goods/import_files, offers/import_files)
        # –£–¥–∞–ª—è–µ–º —Å–∞–º–∏ –ø–∞–ø–∫–∏ import_files, —Ç–∞–∫ –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–∂–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã –≤ media/products
        img_dirs = []
        if file_type in ["all", "goods"]:
            img_dirs.append(Path(data_dir) / "goods" / "import_files")
        if file_type in ["all", "offers"]:
            img_dirs.append(Path(data_dir) / "offers" / "import_files")

        deleted_img_dir_count = 0
        for img_dir in img_dirs:
            if img_dir.exists() and img_dir.is_dir():
                try:
                    # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã –≤–Ω—É—Ç—Ä–∏ –ø–∞–ø–∫–∏, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–∞–º—É –ø–∞–ø–∫—É
                    files_deleted = 0
                    for img_file in img_dir.iterdir():
                        if img_file.is_file():
                            try:
                                img_file.unlink()
                                files_deleted += 1
                            except OSError:
                                pass

                    if files_deleted > 0:
                        self.stdout.write(
                            f"   ‚úÖ –û—á–∏—â–µ–Ω–∞ –ø–∞–ø–∫–∞ {img_dir.relative_to(data_dir)}: —É–¥–∞–ª–µ–Ω–æ {files_deleted} —Ñ–∞–π–ª–æ–≤"
                        )
                        deleted_img_dir_count += 1
                except OSError as e:
                    self.stdout.write(self.style.ERROR(f"   ‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–ø–∫–∏ {img_dir.name}: {e}"))

    def _clear_existing_data(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        self.stdout.write(
            self.style.WARNING(
                "\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤, –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤, " "–∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ –±—Ä–µ–Ω–¥–æ–≤..."
            )
        )
        confirm = input("–í—ã —É–≤–µ—Ä–µ–Ω—ã? –í–≤–µ–¥–∏—Ç–µ 'yes' –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: ")

        if confirm.lower() == "yes":
            ProductVariant.objects.all().delete()
            Product.objects.all().delete()
            Category.objects.all().delete()
            Brand.objects.all().delete()
            self.stdout.write(self.style.SUCCESS("‚úÖ –î–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã"))
        else:
            self.stdout.write(self.style.ERROR("‚ùå –û—á–∏—Å—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞"))
            raise CommandError("–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")

    def _print_stats(self, stats: dict) -> None:
        """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–º–ø–æ—Ä—Ç–∞"""
        self.stdout.write("\n" + "=" * 60)
        self.stdout.write(self.style.SUCCESS("‚úÖ –ò–ú–ü–û–†–¢ –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û"))
        self.stdout.write("=" * 60)
        self.stdout.write("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        self.stdout.write(f"   Products —Å–æ–∑–¥–∞–Ω–æ:        {stats.get('products_created', 0)}")
        self.stdout.write(f"   Products –æ–±–Ω–æ–≤–ª–µ–Ω–æ:      {stats.get('products_updated', 0)}")
        self.stdout.write(f"   Variants —Å–æ–∑–¥–∞–Ω–æ:        {stats.get('variants_created', 0)}")
        self.stdout.write(f"   Variants –æ–±–Ω–æ–≤–ª–µ–Ω–æ:      {stats.get('variants_updated', 0)}")
        self.stdout.write(f"   Default variants:        {stats.get('default_variants_created', 0)}")
        self.stdout.write(f"   –¶–µ–Ω –æ–±–Ω–æ–≤–ª–µ–Ω–æ:           {stats.get('prices_updated', 0)}")
        self.stdout.write(f"   –û—Å—Ç–∞—Ç–∫–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–æ:      {stats.get('stocks_updated', 0)}")
        self.stdout.write(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ:               {stats.get('skipped', 0)}")
        self.stdout.write(f"   –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π:          {stats.get('warnings', 0)}")
        self.stdout.write(f"   –û—à–∏–±–æ–∫:                  {stats.get('errors', 0)}")

        self.stdout.write("\nüì∏ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø:")
        self.stdout.write(f"   –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ:             {stats.get('images_copied', 0)}")
        self.stdout.write(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ (—Å—É—â–µ—Å—Ç–≤—É—é—Ç):  {stats.get('images_skipped', 0)}")
        self.stdout.write(f"   –û—à–∏–±–æ–∫:                  {stats.get('images_errors', 0)}")
        self.stdout.write("=" * 60)

    def _collect_xml_files(self, base_dir: str, subdir: str, filename: str) -> list[str]:
        """
        –°–±–æ—Ä XML —Ñ–∞–π–ª–æ–≤ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∏–º–µ–Ω –∏ –ø–∞–ø–æ–∫.

        1C —á–∞—Å—Ç–æ –ø—Ä–∏—Å—ã–ª–∞–µ—Ç 'import.xml' –≤–º–µ—Å—Ç–æ 'goods.xml', –∏ —Ñ–∞–π–ª—ã –º–æ–≥—É—Ç
        –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥–ø–∞–ø–∫–∞—Ö –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥—É–ª—è –≤—ã–≥—Ä—É–∑–∫–∏.
        """
        base_path = Path(base_dir) / subdir
        collected: list[Path] = []

        # –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ (–ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ –∏–º—è + —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ 1–°)
        search_filenames = [filename]
        if filename == "goods.xml" or filename == "groups.xml":
            search_filenames.append("import.xml")

        # –°–ø–∏—Å–æ–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞ (–ø–µ—Ä–µ–¥–∞–Ω–Ω–∞—è + –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã)
        search_paths = [base_path]
        if subdir == "groups":
            search_paths.append(Path(base_dir) / "goods")

        for p in search_paths:
            if not p.exists():
                continue

            for fname in search_filenames:
                prefix = fname.replace(".xml", "")

                # 1. –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–º–µ–Ω–∏
                for f_case in [fname, fname.capitalize(), fname.lower()]:
                    direct_file = p / f_case
                    if direct_file.exists() and direct_file not in collected:
                        collected.append(direct_file)

                # 2. –°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (prefix_*.xml) - –∏—â–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
                # –ù–∞ Linux glob('*.xml') —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É
                for pattern in [
                    f"{prefix}_*.xml",
                    f"{prefix.capitalize()}_*.xml",
                    f"{prefix.lower()}_*.xml",
                ]:
                    for segmented_file in sorted(p.glob(pattern)):
                        if segmented_file not in collected:
                            collected.append(segmented_file)

                # 3. Legacy –ø—É—Ç—å (–ø–æ–¥–ø–∞–ø–∫–∞ import_files - –∏–Ω–æ–≥–¥–∞ 1–° –∫–ª–∞–¥–µ—Ç —Ç—É–¥–∞)
                legacy_file = p / "import_files" / fname
                if legacy_file.exists() and legacy_file not in collected:
                    collected.append(legacy_file)

        return [str(path) for path in collected]

    def _dry_run_import(self, data_dir: str) -> None:
        """–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –∏–º–ø–æ—Ä—Ç–∞ –±–µ–∑ –∑–∞–ø–∏—Å–∏ –≤ –ë–î"""
        parser = XMLDataParser()

        self.stdout.write("\nüìã –ü—Ä–æ–≤–µ—Ä–∫–∞ priceLists.xml...")
        price_list_files = self._collect_xml_files(data_dir, "priceLists", "priceLists.xml")
        if price_list_files:
            total = sum(len(parser.parse_price_lists_xml(f)) for f in price_list_files)
            self.stdout.write(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–∏–ø–æ–≤ —Ü–µ–Ω: {total}")
        else:
            self.stdout.write("   ‚ö†Ô∏è –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        self.stdout.write("\nüì¶ –ü—Ä–æ–≤–µ—Ä–∫–∞ goods.xml...")
        goods_files = self._collect_xml_files(data_dir, "goods", "goods.xml")
        if goods_files:
            total = sum(len(parser.parse_goods_xml(f)) for f in goods_files)
            self.stdout.write(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ (Product): {total}")
        else:
            self.stdout.write("   ‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        self.stdout.write("\nüéÅ –ü—Ä–æ–≤–µ—Ä–∫–∞ offers.xml...")
        offers_files = self._collect_xml_files(data_dir, "offers", "offers.xml")
        if offers_files:
            total = sum(len(parser.parse_offers_xml(f)) for f in offers_files)
            self.stdout.write(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (ProductVariant): {total}")
        else:
            self.stdout.write("   ‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        self.stdout.write("\nüí∞ –ü—Ä–æ–≤–µ—Ä–∫–∞ prices.xml...")
        prices_files = self._collect_xml_files(data_dir, "prices", "prices.xml")
        if prices_files:
            total = sum(len(parser.parse_prices_xml(f)) for f in prices_files)
            self.stdout.write(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Ü–µ–Ω: {total}")
        else:
            self.stdout.write("   ‚ö†Ô∏è –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        self.stdout.write("\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ rests.xml...")
        rests_files = self._collect_xml_files(data_dir, "rests", "rests.xml")
        if rests_files:
            total = sum(len(parser.parse_rests_xml(f)) for f in rests_files)
            self.stdout.write(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –æ—Å—Ç–∞—Ç–∫–æ–≤: {total}")
        else:
            self.stdout.write("   ‚ö†Ô∏è –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        self.stdout.write("\n" + "=" * 60)
        self.stdout.write(self.style.SUCCESS("‚úÖ DRY RUN –ó–ê–í–ï–†–®–ï–ù: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞"))
        self.stdout.write("=" * 60)
